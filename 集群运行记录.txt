# 环境安装
clone 下来后
git submodule update --init --recursive

# 安装
conda create --name detic python=3.8 -y
conda activate detic
conda install pytorch==1.12.0 torchvision==0.13.0 cudatoolkit=11.3 -c pytorch -c conda-forge

有时候会报错，可以根据报错信息，手动安装
conda install certifi=2022.9.24=pyhd8ed1ab_0 -c conda-forge
conda install pytorch==1.12.0 torchvision==0.13.0 cudatoolkit=11.3 -c pytorch -c conda-forge

export PATH=/usr/local/cuda-11.3/bin/:$PATH
nvcc -V

git clone git@github.com:facebookresearch/detectron2.git
cd detectron2
pip install -e .

cd ..
pip install -r requirements.txt -i http://pypi.tuna.tsinghua.edu.cn/simple

验证是否成功
wget https://dl.fbaipublicfiles.com/detic/Detic_OVCOCO_CLIP_R50_1x_max-size_caption.pth
python demo.py --config-file configs/Detic_OVCOCO_CLIP_R50_1x_max-size_caption.yaml --input desk.jpg --output out.jpg --vocabulary coco --opts MODEL.WEIGHTS models/Detic_OVCOCO_CLIP_R50_1x_max-size_caption.pth

# 数据准备
软链接 coco 数据到 datasets 下

第一步生成 coco-zero-shot 文件夹
python create_ov_coco_json.py
python tools/get_coco_zeroshot_oriorder.py --data_path datasets/coco-zero-shot/instances_train2017_seen_2.json
python tools/get_coco_zeroshot_oriorder.py --data_path datasets/coco-zero-shot/instances_val2017_all_2.json
python tools/get_lvis_cat_info.py --ann datasets/coco-zero-shot/instances_train2017_seen_2_oriorder.json
python tools/get_cc_tags.py --cc_ann dataset/coco/annotations/captions_train2017.json --out_path datasets/coco-zero-shot/captions_train2017_tags_allcaps.json --allcaps --convert_caption --cat_path dataset/coco/annotations/instances_val2017.json

评估
python train_net.py --num-gpus 8 --config-file configs/Detic_OVCOCO_CLIP_R50_1x_max-size_caption.yaml --eval-only MODEL.WEIGHTS models/Detic_OVCOCO_CLIP_R50_1x_max-size_caption.pth

# 第一步训练 bbox_sup
python train_net.py --num-gpus 8 --config-file configs/BoxSup_OVCOCO_CLIP_R50_1x.yaml
# 第二步训练，需要利用第一步权重
python train_net.py --num-gpus 8 --config-file configs/Detic_OVCOCO_CLIP_R50_1x_max-size_caption.yaml
